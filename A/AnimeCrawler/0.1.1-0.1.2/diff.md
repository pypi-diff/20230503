# Comparing `tmp/AnimeCrawler-0.1.1.tar.gz` & `tmp/AnimeCrawler-0.1.2.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "AnimeCrawler-0.1.1.tar", last modified: Thu Apr 20 12:53:34 2023, max compression
+gzip compressed data, was "AnimeCrawler-0.1.2.tar", last modified: Wed May  3 03:36:47 2023, max compression
```

## Comparing `AnimeCrawler-0.1.1.tar` & `AnimeCrawler-0.1.2.tar`

### file list

```diff
@@ -1,27 +1,29 @@
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.212812 AnimeCrawler-0.1.1/
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.093887 AnimeCrawler-0.1.1/AnimeCrawler/
--rw-rw-rw-   0        0        0      248 2023-04-18 15:03:38.000000 AnimeCrawler-0.1.1/AnimeCrawler/__init__.py
--rw-rw-rw-   0        0        0      311 2023-04-19 14:06:47.000000 AnimeCrawler-0.1.1/AnimeCrawler/__main__.py
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.167838 AnimeCrawler-0.1.1/AnimeCrawler/command/
--rw-rw-rw-   0        0        0       87 2023-04-17 15:39:52.000000 AnimeCrawler-0.1.1/AnimeCrawler/command/__init__.py
--rw-rw-rw-   0        0        0     3542 2023-04-20 12:45:39.000000 AnimeCrawler-0.1.1/AnimeCrawler/command/run.py
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.194822 AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/
--rw-rw-rw-   0        0        0      245 2023-04-17 15:39:52.000000 AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/__init__.py
--rw-rw-rw-   0        0        0     2024 2023-04-17 15:39:52.000000 AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/downloader.py
--rw-rw-rw-   0        0        0     3846 2023-04-19 13:04:13.000000 AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/spider.py
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.205821 AnimeCrawler-0.1.1/AnimeCrawler/utils/
--rw-rw-rw-   0        0        0      113 2023-04-17 15:39:52.000000 AnimeCrawler-0.1.1/AnimeCrawler/utils/__init__.py
--rw-rw-rw-   0        0        0      804 2023-04-17 15:39:52.000000 AnimeCrawler-0.1.1/AnimeCrawler/utils/decode.py
--rw-rw-rw-   0        0        0     2131 2023-04-19 13:15:05.000000 AnimeCrawler-0.1.1/AnimeCrawler/utils/file.py
-drwxrwxrwx   0        0        0        0 2023-04-20 12:53:34.147849 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/
--rw-rw-rw-   0        0        0     3411 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0      535 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0       63 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/entry_points.txt
--rw-rw-rw-   0        0        0       19 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/requires.txt
--rw-rw-rw-   0        0        0       13 2023-04-20 12:53:33.000000 AnimeCrawler-0.1.1/AnimeCrawler.egg-info/top_level.txt
--rw-rw-rw-   0        0        0     1083 2023-04-15 13:28:24.000000 AnimeCrawler-0.1.1/LICENSE
--rw-rw-rw-   0        0        0     3411 2023-04-20 12:53:34.208814 AnimeCrawler-0.1.1/PKG-INFO
--rw-rw-rw-   0        0        0     2962 2023-04-20 12:31:36.000000 AnimeCrawler-0.1.1/README.md
--rw-rw-rw-   0        0        0       42 2023-04-20 12:53:34.213812 AnimeCrawler-0.1.1/setup.cfg
--rw-rw-rw-   0        0        0      908 2023-04-20 12:52:40.000000 AnimeCrawler-0.1.1/setup.py
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.215752 AnimeCrawler-0.1.2/
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.136797 AnimeCrawler-0.1.2/AnimeCrawler/
+-rw-rw-rw-   0        0        0      353 2023-05-03 02:47:47.000000 AnimeCrawler-0.1.2/AnimeCrawler/__init__.py
+-rw-rw-rw-   0        0        0      281 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/__main__.py
+-rw-rw-rw-   0        0        0     2198 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/base_spider.py
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.185769 AnimeCrawler-0.1.2/AnimeCrawler/command/
+-rw-rw-rw-   0        0        0       76 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/command/__init__.py
+-rw-rw-rw-   0        0        0     2912 2023-05-03 03:12:56.000000 AnimeCrawler-0.1.2/AnimeCrawler/command/run.py
+-rw-rw-rw-   0        0        0      356 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/log.py
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.193771 AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/
+-rw-rw-rw-   0        0        0      256 2023-05-03 02:47:31.000000 AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/__init__.py
+-rw-rw-rw-   0        0        0     2286 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/downloader.py
+-rw-rw-rw-   0        0        0     4172 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/spider.py
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.211754 AnimeCrawler-0.1.2/AnimeCrawler/utils/
+-rw-rw-rw-   0        0        0      121 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/utils/__init__.py
+-rw-rw-rw-   0        0        0     1403 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/utils/decode.py
+-rw-rw-rw-   0        0        0     2154 2023-05-03 02:47:10.000000 AnimeCrawler-0.1.2/AnimeCrawler/utils/file.py
+drwxrwxrwx   0        0        0        0 2023-05-03 03:36:47.179773 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/
+-rw-rw-rw-   0        0        0     3406 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/PKG-INFO
+-rw-rw-rw-   0        0        0      583 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/SOURCES.txt
+-rw-rw-rw-   0        0        0        1 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/dependency_links.txt
+-rw-rw-rw-   0        0        0       63 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/entry_points.txt
+-rw-rw-rw-   0        0        0       27 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/requires.txt
+-rw-rw-rw-   0        0        0       13 2023-05-03 03:36:46.000000 AnimeCrawler-0.1.2/AnimeCrawler.egg-info/top_level.txt
+-rw-rw-rw-   0        0        0     1083 2023-04-15 13:28:24.000000 AnimeCrawler-0.1.2/LICENSE
+-rw-rw-rw-   0        0        0     3406 2023-05-03 03:36:47.213753 AnimeCrawler-0.1.2/PKG-INFO
+-rw-rw-rw-   0        0        0     2957 2023-05-03 02:19:56.000000 AnimeCrawler-0.1.2/README.md
+-rw-rw-rw-   0        0        0       42 2023-05-03 03:36:47.215752 AnimeCrawler-0.1.2/setup.cfg
+-rw-rw-rw-   0        0        0      884 2023-05-03 03:31:04.000000 AnimeCrawler-0.1.2/setup.py
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/downloader.py` & `AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/downloader.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,62 +1,71 @@
 import asyncio
 
 import aiohttp
 import tqdm.asyncio
 
+from AnimeCrawler.log import get_logger
 from AnimeCrawler.utils import write
 
 
 class Downloader:
     session = None
-
-    def __init__(self, urls):
-        self.urls = urls
+    logger = get_logger('Downloader')
 
     @property
-    def current_sesion(self):
+    def current_session(self):
         if not self.session:
             self.session = aiohttp.ClientSession(
-                connector=aiohttp.TCPConnector(limit=40, verify_ssl=False)
+                connector = aiohttp.TCPConnector(verify_ssl=False)
             )
+            self.logger.debug('åˆ›å»ºäº†session')
         return self.session
 
+    @property
+    def set_url(self, urls):
+        return urls
+
+    @set_url.setter
+    def set_url(self, urls):
+        self.urls = urls
+
+    async def close_session(self):
+        await self.current_session.close()
+
     async def get_ts_file(
         self,
+        session: aiohttp.ClientSession,
         title: str,
         url: str,
         error_times: int = 1,
     ):
-        resp = await self.current_sesion.get(
+        resp = await session.get(
             url=url,
             headers={'User-Agent': 'Mozilla/5.0', ' Transfer-Encoding': 'chunked'},
         )
         try:
             text = await resp.content.read()
+            await asyncio.sleep(0)
             return (text, title)
         except aiohttp.ClientPayloadError as e:  # æŠ¥é”™æ—¶é‡æ–°ä¸‹è½½
             if error_times == 3:
                 raise Warning(f'ä¸‹è½½{title}.tsæ—¶å‘ç”Ÿé”™è¯¯') from e
             print(f'ä¸‹è½½{title}.tsæ—¶å‘ç”Ÿé”™è¯¯ï¼Œæ­£åœ¨é‡è¯•ç¬¬{error_times}æ¬¡')
-            return await self.get_ts_file(title, url, error_times + 1)
+            return await self.get_ts_file(session, title, url, error_times + 1)
         except Exception as e:
-            print(f'ä¸‹è½½{title}.tsæ—¶å‘ç”Ÿ{e}')
-            await asyncio.sleep(0)
+            raise ValueError(f'ä¸‹è½½{title}.tsæ—¶ï¼Œ{e}') from e
         finally:
             resp.close()
 
-    async def close_session(self):
-        if self.session:
-            await self.session.close()
-
     async def download_ts_files(self, path, episodes):
         tasks = [
-            self.get_ts_file(str(index).zfill(4), url)
+            self.get_ts_file(self.current_session, str(index).zfill(4), url)
             for index, url in enumerate(self.urls)
         ]
-        for task in tqdm.asyncio.tqdm.as_completed(tasks, desc=f"æ­£åœ¨ä¸‹è½½ç¬¬{episodes}é›†è§†é¢‘"):
+        for task in tqdm.asyncio.tqdm.as_completed(
+            tasks, desc=f"æ­£åœ¨ä¸‹è½½ç¬¬{episodes}é›†è§†é¢‘", delay=3
+        ):
             result = await task
             text_1, title = (
                 (b'error', 'error') if result is None else result
             )  # resultä¸ºç©ºæ—¶è¿”å›'error'
             await write(path, text_1, title, suffix='ts', mode='wb')
-        await self.close_session()
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler/mhyyy/spider.py` & `AnimeCrawler-0.1.2/AnimeCrawler/mhyyy/spider.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 import re
 from pathlib import Path
 
-from ruia import Item, Response, Spider, TextField
+from ruia import Item, Response, TextField
 
+from AnimeCrawler.base_spider import BaseSpider
+from AnimeCrawler.log import get_logger
 from AnimeCrawler.utils import (
     base64_decode,
     folder_path,
     get_video_path,
     merge_ts2mp4,
     unescape,
     write,
@@ -19,42 +21,43 @@
     target_item = TextField(xpath_select='//div[@class="player-box-main"]')
     profile = TextField(xpath_select='//div/script[@type="text/javascript"]')
     episodes = None
     _base_m3u8_url = None
     mixed_m3u8_url = None
 
 
-class AnimeSpider(Spider):
+class AnimeSpider(BaseSpider):
     _base_ts_url = None
     _mixed_m3u8 = None
+    downloader = Downloader()
     headers = {'User-Agent': 'Mozilla/5.0'}
 
     @classmethod
-    def init(cls, anime_title: str, start_urls: str, del_ts: bool = False):
+    def init(cls, anime_title: str, urls: str, del_ts: bool = False):
         '''åˆå§‹åŒ–çˆ¬è™«
 
         Args:
             anime_title (str): åŠ¨æ¼«æ ‡é¢˜ï¼Œç”¨äºå–æ–‡ä»¶å¤¹çš„åç§°ï¼Œåˆ©äºç®¡ç†åŠ¨æ¼«
-            start_urls (str): ç¬¬ä¸€é¡µçš„ç½‘å€
+            urls (str): ç¬¬ä¸€é¡µçš„ç½‘å€
 
         Returns:
             cls: ä¸ºäº†é“¾å¼è°ƒç”¨è¿”å›äº†cls
         '''
-        cls.start_urls = [start_urls]
+        cls.domain = cls.get_domain(cls, urls)
+        cls.start_urls = [cls.get_path(cls, urls)]
+        cls.PATH = folder_path(Path(get_video_path()) / anime_title)
         cls.del_ts = del_ts
-        video_path = Path(get_video_path()) / anime_title  # åœ¨é¡¹ç›®ç›®å½•ä¸‹å­˜å‚¨
-        cls.PATH = folder_path(video_path)
-        return cls
+        return super().init()
 
     async def _mixed_m3u8_url_parse(self, index_m3u8_url: str, item: AnimeItem) -> None:
         resp = await self.request(index_m3u8_url).fetch()
         text = await resp.text()
         if self._mixed_m3u8 is None:
             self._mixed_m3u8 = text.split('\n')[-1]
-        item.mixed_m3u8_url = item._base_m3u8_url + self._mixed_m3u8
+        item.mixed_m3u8_url = await self.urljoin(item._base_m3u8_url, self._mixed_m3u8)
 
     def _parse_mixed_m3u8(self, item: AnimeItem):
         '''è§£æmixed.m3u8æ–‡ä»¶ï¼Œè·å¾—tsæ–‡ä»¶ä¸‹è½½åœ°å€
 
         Returns:
             strï¼šts_url
         '''
@@ -63,16 +66,16 @@
             for i in fp:
                 if '#' not in i:
                     yield base_ts_file + i
 
     async def have_next_page(self, link_next: str):
         # å½“æœ‰ä¸‹ä¸€é¡µæ—¶
         link_next = link_next.replace('\\', '')
-        return self.request(
-            'https://www.mhyyy.com' + link_next,
+        return await self.follow(
+            await self.urljoin(self.domain, link_next),
             callback=self.parse,
             headers=self.headers,
         )
 
     async def parse(self, response: Response):
         async for item in AnimeItem.get_items(html=await response.text()):
             profile = item.profile
@@ -91,17 +94,22 @@
             yield item
 
     async def process_item(self, item: AnimeItem):
         resp = await self.request(item.mixed_m3u8_url, headers=self.headers).fetch()
         text = await resp.text()
         episodes = item.episodes
         folder_path = self.PATH / f'{episodes}'
-        print('\033[0;32;40må†™å…¥mixed.m3u8\033[0m')
+        self.logger.info('\033[0;32;40må†™å…¥mixed.m3u8\033[0m')
         await write(folder_path, text, 'mixed', 'm3u8', 'w+')
         urls = self._parse_mixed_m3u8(item)
-        await Downloader(urls).download_ts_files(folder_path, episodes)
+        self.downloader.set_url = urls
+        await self.downloader.download_ts_files(folder_path, episodes)
         self.logger.info(f"æ­£åœ¨æŠŠç¬¬ {episodes} é›†çš„tsæ–‡ä»¶è½¬ç æˆ mp4")
         await merge_ts2mp4(folder_path, episodes, self.del_ts)
 
+    async def stop(self, _signal):
+        await self.downloader.close_session()
+        return await super().stop(_signal)
+
 
 if __name__ == '__main__':
     AnimeSpider.init('é­”å¥³ä¹‹æ—…', ['https://www.mhyyy.com/play/166269-1-1.html']).start()
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler/utils/decode.py` & `AnimeCrawler-0.1.2/AnimeCrawler/utils/decode.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,13 +1,34 @@
 import html
 import re
 import urllib.parse
 from base64 import b64decode
 
 
+def is_url(string: str):
+    '''è§£ææ˜¯å¦ä¸ºurl
+
+    Args:
+        string (str): è¦è§£æçš„å­—ç¬¦ä¸²
+
+    Returns:
+        bool: ç”¨äºåˆ¤æ–­
+    '''
+    pattern = re.compile(
+        r'^(?:http|ftp)s?://'  # http:// or https://
+        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|'  # domain...
+        r'localhost|'  # localhost...
+        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
+        r'(?::\d+)?'  # optional port
+        r'(?:/?|[/?]\S+)$',
+        re.IGNORECASE,
+    )
+    return bool(re.search(pattern, string))
+
+
 def base64_decode(string: str) -> str:
     '''å¯¹base64.b64decode()çš„åŒ…è£…
 
     Arguments:
         string -- è¦è§£ç çš„å­—ç¬¦ä¸²
 
     Returns:
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler/utils/file.py` & `AnimeCrawler-0.1.2/AnimeCrawler/utils/file.py`

 * *Files 18% similar despite different names*

```diff
@@ -62,15 +62,14 @@
 async def merge_ts2mp4(folder_path: Path, episodes: int = None, del_ts: bool = False):
     '''å°†tsæ–‡ä»¶åˆå¹¶æˆmp4
 
     Args:
         folder_path (Path): æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé‡Œé¢åº”æœ‰tsæ–‡ä»¶
         episodes (int): åŠ¨æ¼«é›†æ•°. Defaults to None.
     '''
-    print(del_ts)
     for file_path in folder_path.iterdir():
         if file_path.suffix == '.ts':
-            with open(file_path, 'rb') as f1:
-                with open(folder_path / f"ç¬¬{episodes}é›†.mp4", 'ab') as f2:
-                    f2.write(f1.read())
+            async with aiofiles.open(file_path, 'rb') as f1:
+                async with aiofiles.open(folder_path / f"ç¬¬{episodes}é›†.mp4", 'ab') as f2:
+                    await f2.write(await f1.read())
             if del_ts:
                 file_path.unlink()
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler.egg-info/PKG-INFO` & `AnimeCrawler-0.1.2/AnimeCrawler.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: AnimeCrawler
-Version: 0.1.1
+Version: 0.1.2
 Summary: ä¸€ä¸ªå¯å…è´¹ä¸‹è½½åŠ¨æ¼«çš„çˆ¬è™«
 Home-page: https://github.com/Senvlin/AnimeCrawler
 Author: Senvlin
 Author-email: 2994515402@qq.com
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
@@ -28,16 +28,16 @@
 
 è¿™æ˜¯ä¸€æ¬¾åœ¨Windowså¹³å°ä¸‹åŸºäºè½»é‡çº§æ¡†æ¶<code>[**Ruia**](https://github.com/howie6879/ruia)</code>ã€ä¸“é—¨çˆ¬å–å…è´¹åŠ¨æ¼«çš„çˆ¬è™«ï¼Œåº•å±‚ä½¿ç”¨<code>aiohttp</code>åº“ï¼Œä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œå¤§å¹…å¢åŠ çˆ¬å–åŠä¸‹è½½é€Ÿåº¦ã€‚å¯**ç¦»çº¿æ’­æ”¾**å„å¤§åŠ¨æ¼«ï¼Œæ”¯æŒ**å‘½ä»¤è¡Œè¾“å…¥**ï¼Œç«‹å¿—æˆä¸ºæœ€å®ç”¨ï¼Œæœ€è½»é‡çš„åŠ¨æ¼«ç®¡ç†åŠä¸‹è½½åŠ©æ‰‹
 
 ## â“å¦‚ä½•ä½¿ç”¨
 1. é¦–å…ˆæ¥åˆ°[è¿™é‡Œ](https://www.python.org/downloads)ä¸‹è½½Pythonè§£é‡Šå™¨, è¦æ±‚Python3.8åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå®‰è£…å³å¯
 2. ç„¶åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>pip install AnimeCrawler</code>
 3. å…¶æ¬¡ï¼Œæ¥åˆ°[è¿™ä¸ªç½‘ç«™](https://www.mhyyy.com/),æœç´¢æ‚¨å–œæ¬¢çš„åŠ¨æ¼«ï¼Œç‚¹å‡»æ’­æ”¾é¡µï¼Œå°†ç¬¬ä¸€é¡µçš„urlå¤åˆ¶ä¸€ä¸‹
-4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>python -m AnimeCrawler "åŠ¨æ¼«åç§°" "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
-    - è¾“å…¥ <code>python -m AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
+4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>AnimeCrawler download -t "åŠ¨æ¼«åç§°" -u "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
+    - è¾“å…¥ <code>AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
 > ä¸‹è½½åçš„æ–‡ä»¶åœ¨æ‚¨çš„è§†é¢‘æ–‡ä»¶å¤¹é‡Œ
 
 å¦‚æœæ‚¨æƒ³ä½“éªŒæœ€æ–°çš„åŠŸèƒ½ï¼Œè¯·è½¬åˆ°devåˆ†æ”¯~
 
 ## ğŸš€æˆ‘æƒ³å¸®å¿™
 ååˆ†æ„Ÿè°¢æ‚¨æœ‰è¿™ä¸ªæƒ³æ³•ã€‚è¿™ä¸ªé¡¹ç›®ä»åœ¨é’æ¶©å¹´åï¼Œæ€»ä¼šæœ‰ä¸€äº›è·Œè·Œæ’æ’çš„æ—¶å€™ï¼Œä¹Ÿè®¸æ‚¨çš„ä¸¾æ‰‹ä¹‹åŠ³ï¼Œèƒ½é€ å°±æ›´å¥½çš„å®ƒ
```

### Comparing `AnimeCrawler-0.1.1/AnimeCrawler.egg-info/SOURCES.txt` & `AnimeCrawler-0.1.2/AnimeCrawler.egg-info/SOURCES.txt`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 LICENSE
 README.md
 setup.py
 AnimeCrawler/__init__.py
 AnimeCrawler/__main__.py
+AnimeCrawler/base_spider.py
+AnimeCrawler/log.py
 AnimeCrawler.egg-info/PKG-INFO
 AnimeCrawler.egg-info/SOURCES.txt
 AnimeCrawler.egg-info/dependency_links.txt
 AnimeCrawler.egg-info/entry_points.txt
 AnimeCrawler.egg-info/requires.txt
 AnimeCrawler.egg-info/top_level.txt
 AnimeCrawler/command/__init__.py
```

### Comparing `AnimeCrawler-0.1.1/LICENSE` & `AnimeCrawler-0.1.2/LICENSE`

 * *Files identical despite different names*

### Comparing `AnimeCrawler-0.1.1/PKG-INFO` & `AnimeCrawler-0.1.2/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: AnimeCrawler
-Version: 0.1.1
+Version: 0.1.2
 Summary: ä¸€ä¸ªå¯å…è´¹ä¸‹è½½åŠ¨æ¼«çš„çˆ¬è™«
 Home-page: https://github.com/Senvlin/AnimeCrawler
 Author: Senvlin
 Author-email: 2994515402@qq.com
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
@@ -28,16 +28,16 @@
 
 è¿™æ˜¯ä¸€æ¬¾åœ¨Windowså¹³å°ä¸‹åŸºäºè½»é‡çº§æ¡†æ¶<code>[**Ruia**](https://github.com/howie6879/ruia)</code>ã€ä¸“é—¨çˆ¬å–å…è´¹åŠ¨æ¼«çš„çˆ¬è™«ï¼Œåº•å±‚ä½¿ç”¨<code>aiohttp</code>åº“ï¼Œä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œå¤§å¹…å¢åŠ çˆ¬å–åŠä¸‹è½½é€Ÿåº¦ã€‚å¯**ç¦»çº¿æ’­æ”¾**å„å¤§åŠ¨æ¼«ï¼Œæ”¯æŒ**å‘½ä»¤è¡Œè¾“å…¥**ï¼Œç«‹å¿—æˆä¸ºæœ€å®ç”¨ï¼Œæœ€è½»é‡çš„åŠ¨æ¼«ç®¡ç†åŠä¸‹è½½åŠ©æ‰‹
 
 ## â“å¦‚ä½•ä½¿ç”¨
 1. é¦–å…ˆæ¥åˆ°[è¿™é‡Œ](https://www.python.org/downloads)ä¸‹è½½Pythonè§£é‡Šå™¨, è¦æ±‚Python3.8åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå®‰è£…å³å¯
 2. ç„¶åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>pip install AnimeCrawler</code>
 3. å…¶æ¬¡ï¼Œæ¥åˆ°[è¿™ä¸ªç½‘ç«™](https://www.mhyyy.com/),æœç´¢æ‚¨å–œæ¬¢çš„åŠ¨æ¼«ï¼Œç‚¹å‡»æ’­æ”¾é¡µï¼Œå°†ç¬¬ä¸€é¡µçš„urlå¤åˆ¶ä¸€ä¸‹
-4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>python -m AnimeCrawler "åŠ¨æ¼«åç§°" "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
-    - è¾“å…¥ <code>python -m AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
+4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>AnimeCrawler download -t "åŠ¨æ¼«åç§°" -u "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
+    - è¾“å…¥ <code>AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
 > ä¸‹è½½åçš„æ–‡ä»¶åœ¨æ‚¨çš„è§†é¢‘æ–‡ä»¶å¤¹é‡Œ
 
 å¦‚æœæ‚¨æƒ³ä½“éªŒæœ€æ–°çš„åŠŸèƒ½ï¼Œè¯·è½¬åˆ°devåˆ†æ”¯~
 
 ## ğŸš€æˆ‘æƒ³å¸®å¿™
 ååˆ†æ„Ÿè°¢æ‚¨æœ‰è¿™ä¸ªæƒ³æ³•ã€‚è¿™ä¸ªé¡¹ç›®ä»åœ¨é’æ¶©å¹´åï¼Œæ€»ä¼šæœ‰ä¸€äº›è·Œè·Œæ’æ’çš„æ—¶å€™ï¼Œä¹Ÿè®¸æ‚¨çš„ä¸¾æ‰‹ä¹‹åŠ³ï¼Œèƒ½é€ å°±æ›´å¥½çš„å®ƒ
```

### Comparing `AnimeCrawler-0.1.1/README.md` & `AnimeCrawler-0.1.2/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -14,16 +14,16 @@
 
 è¿™æ˜¯ä¸€æ¬¾åœ¨Windowså¹³å°ä¸‹åŸºäºè½»é‡çº§æ¡†æ¶<code>[**Ruia**](https://github.com/howie6879/ruia)</code>ã€ä¸“é—¨çˆ¬å–å…è´¹åŠ¨æ¼«çš„çˆ¬è™«ï¼Œåº•å±‚ä½¿ç”¨<code>aiohttp</code>åº“ï¼Œä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œå¤§å¹…å¢åŠ çˆ¬å–åŠä¸‹è½½é€Ÿåº¦ã€‚å¯**ç¦»çº¿æ’­æ”¾**å„å¤§åŠ¨æ¼«ï¼Œæ”¯æŒ**å‘½ä»¤è¡Œè¾“å…¥**ï¼Œç«‹å¿—æˆä¸ºæœ€å®ç”¨ï¼Œæœ€è½»é‡çš„åŠ¨æ¼«ç®¡ç†åŠä¸‹è½½åŠ©æ‰‹
 
 ## â“å¦‚ä½•ä½¿ç”¨
 1. é¦–å…ˆæ¥åˆ°[è¿™é‡Œ](https://www.python.org/downloads)ä¸‹è½½Pythonè§£é‡Šå™¨, è¦æ±‚Python3.8åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå®‰è£…å³å¯
 2. ç„¶åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>pip install AnimeCrawler</code>
 3. å…¶æ¬¡ï¼Œæ¥åˆ°[è¿™ä¸ªç½‘ç«™](https://www.mhyyy.com/),æœç´¢æ‚¨å–œæ¬¢çš„åŠ¨æ¼«ï¼Œç‚¹å‡»æ’­æ”¾é¡µï¼Œå°†ç¬¬ä¸€é¡µçš„urlå¤åˆ¶ä¸€ä¸‹
-4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>python -m AnimeCrawler "åŠ¨æ¼«åç§°" "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
-    - è¾“å…¥ <code>python -m AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
+4. æœ€åï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼Œè¾“å…¥ <code>AnimeCrawler download -t "åŠ¨æ¼«åç§°" -u "url"</code> å›è½¦å°±å¯ä»¥ä¸‹è½½å•¦
+    - è¾“å…¥ <code>AnimeCrawler -h</code> ä¼šæœ‰è¯¦ç»†çš„è¯´æ˜
 > ä¸‹è½½åçš„æ–‡ä»¶åœ¨æ‚¨çš„è§†é¢‘æ–‡ä»¶å¤¹é‡Œ
 
 å¦‚æœæ‚¨æƒ³ä½“éªŒæœ€æ–°çš„åŠŸèƒ½ï¼Œè¯·è½¬åˆ°devåˆ†æ”¯~
 
 ## ğŸš€æˆ‘æƒ³å¸®å¿™
 ååˆ†æ„Ÿè°¢æ‚¨æœ‰è¿™ä¸ªæƒ³æ³•ã€‚è¿™ä¸ªé¡¹ç›®ä»åœ¨é’æ¶©å¹´åï¼Œæ€»ä¼šæœ‰ä¸€äº›è·Œè·Œæ’æ’çš„æ—¶å€™ï¼Œä¹Ÿè®¸æ‚¨çš„ä¸¾æ‰‹ä¹‹åŠ³ï¼Œèƒ½é€ å°±æ›´å¥½çš„å®ƒ
```

### Comparing `AnimeCrawler-0.1.1/setup.py` & `AnimeCrawler-0.1.2/setup.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,32 +1,28 @@
 import setuptools
 
 with open("README.md", "r", encoding='utf-8') as fh:
     long_description = fh.read()
 
 setuptools.setup(
     name="AnimeCrawler",
-    version="v0.1.1",
+    version="v0.1.2",
     author="Senvlin",
     author_email="2994515402@qq.com",
     description="ä¸€ä¸ªå¯å…è´¹ä¸‹è½½åŠ¨æ¼«çš„çˆ¬è™«",
     long_description=long_description,
     long_description_content_type="text/markdown",
     url="https://github.com/Senvlin/AnimeCrawler",
     packages=setuptools.find_packages(),
     classifiers=[
         "Programming Language :: Python :: 3",
         "License :: OSI Approved :: MIT License",
         "Operating System :: OS Independent",
     ],
-    install_requires=[
-        'ruia',
-        'tqdm',
-        'aiofiles',
-    ],
+    install_requires=['ruia', 'tqdm', 'aiofiles', 'aiohttp'],
     entry_points={
         'console_scripts': [
             'animecrawler = AnimeCrawler.command.run:main',
         ],
     },
     python_requires='>=3.8',
 )
```

